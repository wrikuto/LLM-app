{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDFの解析を行うチャットボットの作成\n",
    "\n",
    "\n",
    "本レポートでは、chainlitとlangchainを利用して、PDFを分析するチャットボットの作成についてまとめる。\n",
    "\n",
    "## chainlitとは？\n",
    "本番環境に対応した対話型AIのUIを作るためのライブラリ\n",
    "\n",
    "## langchainとは？\n",
    "大規模言語モデルを利用してアプリケーションを作成するためのフレームワーク。外部のデータベースや言語処理系と組み合わせて、高度な処理を行うアプリケーションを作成することができる。\n",
    "\n",
    "いずれもpip installによってインストールを行う。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アプリケーションの動かし方\n",
    "\n",
    "- 本ドキュメントの最下部に記述されたコードを、任意の.pyファイルに貼り付ける。\n",
    "\n",
    "- 次に、.env というファイルを作成し、その中に次のようにOpenAIのapiキーを記述する。\n",
    "\n",
    "\tOPENAI_API_KEY=あなたのOpenAI APIキー\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- chainlitを起動するためには、.pyファイルが位置するディレクトリにおいて、以下のコマンドを実行する。\n",
    "\n",
    "\tchainlit run ファイル名 -w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の手順が完了すれば、アプリケーションがブラウザ上で起動するはずである。ここで任意のPDFファイルを渡し、質問を行うことができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コードの解説\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリインポート\n",
    "import dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import SpacyTextSplitter\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "import chainlit as cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APIキーの取得\n",
    "\n",
    "まず、dotenvを利用し、.envファイルからapiキーを変数名とともに辞書に格納する。\n",
    "\n",
    "この変数に対し、.get(\"OPENAI_API_KEY\", \"\")でapiキーのみを取得できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'OPENAI_API_KEY': 'hoge'})\n",
      "\n",
      "apiキーを抽出:\n",
      " hoge\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env_values = dotenv.dotenv_values()\n",
    "print(env_values)\n",
    "print(\"\\napiキーを抽出:\\n\", env_values.get(\"OPENAI_API_KEY\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プロンプトテンプレート\n",
    "\n",
    "プロンプトテンプレートとは、言語モデルに入力するプロンプト生成のために事前に定義されるもの。( from langchain.prompts import PromptTemplate )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# プロンプトを定義\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    文章を前提にして質問に答えてください。\n",
    "\n",
    "    文章 :\n",
    "    {document}\n",
    "\n",
    "    質問 : {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"document\", \"question\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ソースコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import SpacyTextSplitter\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "import chainlit as cl\n",
    "\n",
    "env_values = dotenv.dotenv_values()\n",
    "\n",
    "# プロンプトを定義\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    文章を前提にして質問に答えてください。\n",
    "\n",
    "    文章 :\n",
    "    {document}\n",
    "\n",
    "    質問 : {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"document\", \"question\"],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "\t\"\"\"初回起動時に呼び出される.\"\"\"\n",
    "\n",
    "\t# PDFを読み込む処理\n",
    "\tfiles = None\n",
    "\n",
    "\t# awaitメソッドのために、whileを利用する。アップロードされるまで続く。\n",
    "\twhile files is None:\n",
    "\t\t# chainlitの機能に、ファイルをアップロードさせるメソッドがある。\n",
    "\t\tfiles = await cl.AskFileMessage(\n",
    "\t\t\t# ファイルの最大サイズ\n",
    "\t\t\tmax_size_mb=20,\n",
    "\t\t\t# ファイルをアップロードさせる画面のメッセージ\n",
    "\t\t\tcontent=\"PDFを選択してください。\",\n",
    "\t\t\t# PDFファイルを指定する\n",
    "\t\t\taccept=[\"application/pdf\"],\n",
    "\t\t\t# タイムアウトなし\n",
    "\t\t\traise_on_timeout=False,\n",
    "\t\t).send()\n",
    "\n",
    "\tfile = files[0]\n",
    "\n",
    "\t# アップロードされたファイルのパスから中身を読み込む。\n",
    "\tdocuments = PyMuPDFLoader(file.path).load()\n",
    "    \n",
    "    # PDFを分割する処理\n",
    "\ttext_splitter = SpacyTextSplitter(chunk_size=400, pipeline=\"ja_core_news_sm\")\n",
    "\tsplitted_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "    # PDFの内容をベクトル化して保存する処理\n",
    "\t# テキストをベクトル化するOpenAIのモデル\n",
    "\tembeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", api_key=env_values.get(\"OPENAI_API_KEY\", \"\"))\n",
    "\n",
    "\t# Chromaにembedding APIを指定して、初期化する。\n",
    "\tdatabase = Chroma(embedding_function=embeddings)\n",
    "\n",
    "\t# PDFから内容を分割されたドキュメントを保存する。\n",
    "\tdatabase.add_documents(splitted_documents)\n",
    "\n",
    "\t# 今回は、簡易化のためセッションに保存する。\n",
    "\tcl.user_session.set(\"data\", database)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@cl.on_message\n",
    "async def on_message(input_message: cl.Message):\n",
    "\t\"\"\"メッセージが送られるたびに呼び出される.\"\"\"\n",
    "    \n",
    "\t# チャット用のOpenAIのモデル\n",
    "\topen_ai = ChatOpenAI(api_key=env_values.get(\"OPENAI_API_KEY\", \"\"), model=\"gpt-4\") # type: ignore\n",
    "\n",
    "\t# セッションからベクトルストアを取得（この中にPDFの内容がベクトル化されたものが格納されている）\n",
    "\tdatabase = cl.user_session.get(\"data\")\n",
    "\n",
    "\t# 質問された文から似た文字列を、DBより抽出\n",
    "\tdocuments = database.similarity_search(input_message.content)\n",
    "\n",
    "\t# 抽出したものを結合\n",
    "\tdocuments_string = \"\"\n",
    "\tfor document in documents:\n",
    "\t\tdocuments_string += f\"\"\"\n",
    "\t\t---------------------------------------------\n",
    "\t\t{document.page_content}\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t# プロンプトに埋め込みながらOpenAIに送信\n",
    "\tresult = open_ai(\n",
    "\t\t[\n",
    "\t\t\tHumanMessage(\n",
    "\t\t\t\tcontent=prompt.format(\n",
    "\t\t\t\t\tdocument = database,\n",
    "\t\t\t\t\t# query = input_message.content,\n",
    "\t\t\t\t\tquestion = f\"{input_message.content}: {documents}\", # メッセージと一緒にドキュメントの内容も送信\n",
    "\t\t\t\t)\n",
    "\t\t\t)\n",
    "\t\t]\n",
    "\t).content\n",
    "\n",
    "\tawait cl.Message(content=result, author=\"Answer\").send()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考サイト\n",
    "\n",
    "- [chainlit公式サイト](https://docs.chainlit.io/get-started/overview)\n",
    "\n",
    "- [ローカルで気軽にRAGを使って会話することが簡単すぎてビビった。](https://qiita.com/mitsumizo/items/469d79c5e81d9189a9e4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
